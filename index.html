<!doctype html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width">
  <title>Target Re-identification and Multi-Target Multi-Camera Tracking</title>

  <link rel="stylesheet" href="stylesheets/styles.css">
  <link rel="stylesheet" href="stylesheets/github-light.css">


  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  <style>

  </style>

</head>

<body>
  <div class="wrapper">
    <header>
      <h1>ReID and MTMCT</h1>
      <!--
        <p><b>Target Re-identification and <br />Multi-Target Multi-Camera Tracking</b><br />
        A workshop in conjunction with CVPR19</p>
        -->

      <img src="img/eg_duke.png" class="figure-img img-fluid img-rounded" alt="duke">
      <img src="img/eg_market.png" class="figure-img img-fluid img-rounded" alt="duke">
      <!--<img src="img/eg_duke.png" class="figure-img img-fluid img-rounded" alt="duke">-->
      <br><br>
      <p><b>Dates</b>:<br /> 
        Paper submission deadline: 2019 April 7<br /> 
        Rebuttal period: 2019 April 17-21 <br />
        Camera ready deadline: 2019 April 27<br /><br />
        Challenge kick-off: 2019 March 1<br /> 
        Testing data release: 2019 April 1 <br />
        Result submission deadline: 2019 April 30<br />
        <!--Workshop: July 21, 2019-->
      </p>

      <p><b>Navigation:</b>
        <ul style="margin-top:-10px;">
          <li><a href="#challenge">MTMCT and REID Challenge</a></li>
          <li><a href="#cfp">Call for papers</a></li>
          <!--<li><a href="#motivation">Problem definition and motivation</a></li>-->
          <!--<li><a href="#submission">Submission</a></li>-->
          <li><a href="#invited">Keynote speakers</a></li>
          <li><a href="#people">People involved</a></li>
          <li><a href="#contact">Contact</a></li>
        </ul>
      </p>
    </header>
    <section>

      <!--        <h2>

<br>A workshop in conjunction with CVPR 2019</h2>-->
      <h2>2nd Workshop on</h2>
      <h1 style="margin-top:-10px">
        Target Re-identification and <br/>Multi-Target Multi-Camera Tracking<br>
      </h1>
      <hr />

      <h3>In conjunction with CVPR 2019<br/> June 2019, Long Beach</h3>

      <p>The <a href="https://reid-mct.github.io/2017/">1st MTMCT and REID workshop</a> was successfully held in CVPR 2017. 
        In the past two years, the MTMCT and REID community has been fast growing. As such, we are organizing this workshop 
        for a second time, aiming to gather the state-of-the-art technologies and brainstorm for future directions. 
        We are especially welcoming ideas and contributions that embrace the relationship and future of MTMCT and REID, 
        the two deeply connected domains. 
        A distinct feature of this workshop is a MTMCT and REID challenge. The challenge consists of three tracks: multi-camera 
        multi-camera tracking, person REID with same train/test domains, person REID with distinct train/test domains. 
        We hope the workshop will shape the future state of the art in both the academia and industry.<br></p>
      <hr />

      <br>
      <h3>
        <a id="challenge" class="anchor" href="#designer-templates" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>MTMCT and REID Challenge</h3>
      This workshop will hold an international challenge on the topics of person re-identification and multi-target multi-camera tracking (MTMCT). There will be three 
      competition tracks which are briefly described below. The challenge webpage is under construction. <br><br>
      
      <U>Track 1: Multi-Target Multi-Camera Tracking (MTMCT)</U><br>
      In this track, the large-scale training / validation sets will be based on the publicly available DukeMTMC dataset. In testing, participating teams will 
      have access to our testing dataset. Labels of this testing set are only known to the organizers. This testing set (600 identities) is part of the original DukeMTMC dataset, 
      so it has similar data distribution with the training / validation sets.<br><br>
      
      <U>Track 2: Person Re-identification with the Same Train / Test Domain</U><br>
      This track will evaluate the scalability of ReID models. Training and validation data will be made available
      from the DukeMTMC-reID dataset, which have 16,522 training images of 702 identities, 2,228 query images of the other 702 identities
      and 17,661 gallery images (702 ID + 408 distractor ID). For testing, teams will access our testing set, which has a similar data 
      distribution with the training / validation sets. The test set is part of the original DukeMTMC dataset and has 600 identities.<br><br>
      
      <U>Track 3: Person Re-identification with Different Train / Test Domains</U><br>
      To evaluate the generalization ability of algorithms, this track will ask teams to use the publicly available Market-1501 dataset
      for training / validation. This dataset has 32,668 annotated bounding boxes of 1,501 identities. The training and validation sets 
      are roughly equal in size. In testing, the same test set from Track 1 and Track 2 will be used. Since the training / validation 
      sets have different data distributions with the test set, Track 3 will assess the cross-domain generalization ability.<br><br>
      <br>



      <h3>
        <a id="cfp" class="anchor" href="#designer-templates" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Call
        for papers</h3>
      In target re-identification, we define a query as a bounding box of a targe-of-interest such as a pedestrian or a vehicle. We define a database 
      as a collection of image bounding boxes of arbitrary pedestrians or vehicles. Target re-identification aims to find all the database images
      of the same target as the query. In multi-target multi-camera tracking, we use videos captured by multiple cameras. This task aims to place tight 
      bounding boxes to all the targets (e.g. pedestrians). The bounding boxes are partitioned into trajectories, a set of boxes that bound a
      unique target, ordered by time.
      
      In this full-day workshop, we will have invited speakers, poster sessions, oral presentations, as well as a summary of the challenge. 
      We encourage authors to explore the connections between the fields of ReID and MTMCT and some novel ideas. Examples of such questions are:<br>
      <ul>
        <li>How to define and improve the scalabilityof a MTMCT or ReID system?</li>
        <li>How to deal with large-scale indexing and optimization in ReID and MTMCT?</li>
        <li>How much do initial detections influence performance in MTMCT or ReID?</li>
        <li>How to improve the generalization ability of a MTMCT or ReID system?</li>
        <li>How and which ReID descriptors can be integrated into MTMCT systems?</li>
        <li>What can we learn by evaluating a MTMCT system in terms of ReID (and vice-versa)?</li>
        <li>How can ReID and MTMCT benefit each other?</li>
        <li>How can MTMCT and ReID capitalize on recent large-scale datasets?</li>
        <li>Do semantic attributes help in matching identities in ReID and MTMCT?</li>
      </ul>

      <!--<h3>
        <a id="motivation" class="anchor" href="#designer-templates" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Problem
        definitions and motivation</h3>
      Let a query be an image that tightly bounds a single instance of a target of interest (people, vehicles, etc.). Assume that
      a gallery contains images of several targets in this format as well as distractor images with arbitrary content. <i>Target re-identification</i>      retrieves all and only the gallery images of the same target as the query.
      <br><br> Given a set of videos taken by multiple cameras, <i>multi-target multi-camera tracking</i> places tight bounding
      boxes around all targets in the videos and partitions the boxes into sets called trajectories. A trajectory is the
      set of all boxes that bound a unique target, ordered by time.
      <br><br> These two problems are clearly different. However, they share several common aspects as well. <a href="#motivation"
        id="toggle-link">Here</a>, you can find some of the (dis)similarities that we could think of. Can you come up with
      more?
      <br><br>
      <div id="dis-similarities" style="display: none">
        <b>Some differences:</b>
        <ul>
          <li>The gallery in target re-identification may or may not be a set of videos and both targets and queries are assumed
            to have been isolated ahead of time. The input to multi-target multi-camera tracking on the other hand is necessarily
            a set of videos.</li>
          <li>Multi-target multi-camera tracking matches all targets symmetrically while target re-identification distinguishes
            between query and response explicitly.</li>
        </ul>

        <b>Some similarities:</b>
        <ul>
          <li>They assume a semantic notion of “identity” in that only ground truth can tell if the targets in two bounding boxes
            share the same identity.</li>
          <li>They could benefit from a detector that separates targets from non-targets.</li>
          <li>When the gallery in target re-identification is a set of videos, both problems can use similar pre-processing techniques.
            These might rely on knowing the camera topology, considering time elapsed between observations, modeling changes
            in illumination and viewpoint across cameras, etc.</li>
          <li>Both problems require annotated databases of videos or images and some databases can work for both problems.</li>
          <li>Some components of the solution to either problem can be used to solve the other.</li>
        </ul>
      </div>-->

      To submit a new paper to the workshop, you have to do so through the CMT Website (link TBD).<br><br>
      <!--<h3>
        <a id="submission" class="anchor" href="#designer-templates" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Submission</h3>
      <p>
        <a href="https://cmt3.research.microsoft.com/REIDMTMCT2017">CMT website</a>.
        The workshop paper submissions should be in the same format as the main conference. Please refer to the <a href="http://cvpr2017.thecvf.com/submission/main_conference/author_guidelines">CVPR 2017 author guidelines</a>        for more details.
      </p>-->

      <h3>
        <a id="invited" class="anchor" href="#designer-templates" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Invited
        speakers
      </h3>
      TBD <br><br>

      <!--<img src="img/wang.jpg" height="60px" style="float: left; margin-right: 10px;" />
      <p><b>Xiaogang Wang </b> </br>
        Chinese University of Hong Kong</p>

      <img src="img/leal-taixe.jpg" height="60px" style="float: left; margin-right: 10px;" />
      <p><b>Laura Leal-Taixé</b></br>
        Technical University Munich</p>

      <img src="img/milan.jpg" height="60px" style="float: left; margin-right: 10px;" />
      <p><b>Anton Milan</b></br>
        University of Adelaide</p>

      <img src="img/schmid.jpg" height="60px" style="float: left; margin-right: 10px;" />
      <p><b>Cordelia Schmid</b></br>
        INRIA</p>

      <img src="img/ZiyanWu.jpg" height="60px" style="float: left; margin-right: 10px;" />
      <p><b>Ziyan Wu </b></br>
        Siemens</p>

      <img src="img/zheng.jpg" height="60px" style="float: left; margin-right: 10px;" />
      <p><b>Wei-Shi Zheng</b></br>
        Sun Yat-sen University</p>

      <img src="img/XianshengHua.jpg" height="60px" style="float: left; margin-right: 10px;" />
      <p><b>Xian-Sheng Hua</b></br>
        Alibaba</p>

      <img src="img/shah.jpg" height="60px" style="float: left; margin-right: 10px;" />
      <p><b>Mubarak Shah</b></br>
        University of Central Florida</p>

      <img src="img/roy-chowdhury.jpg" height="60px" style="float: left; margin-right: 10px;" />
      <p><b>Amit Roy-Chowdhury </b> </br>
        University of California Riverside</p>-->


      <b></b><br>
      <h3>
        <a id="people" class="anchor" href="#designer-templates" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>People
        involved
      </h3>
      <b>Organizers:</b><br>
      <img src="img/ristani.jpg" class="figure-img img-fluid img-rounded" alt="" height="60px;">
      <img src="img/liang.jpg" class="figure-img img-fluid img-rounded" alt="" height="60px;">
      <img src="img/eddy.png" class="figure-img img-fluid img-rounded" alt="" height="60px;">
      <img src="img/jwang.jpg" class="figure-img img-fluid img-rounded" alt="" height="60px;">
      <img src="img/zhang.jpg" class="figure-img img-fluid img-rounded" alt="" height="60px;">
      <img src="img/gong.jpg" class="figure-img img-fluid img-rounded" alt="" height="60px;">
      <img src="img/tian.jpg" class="figure-img img-fluid img-rounded" alt="" height="60px;">
      <img src="img/tomasi.jpg" class="figure-img img-fluid img-rounded" alt="" height="60px;">
      <img src="img/richard.jpg" class="figure-img img-fluid img-rounded" alt="" height="60px;">
      <br> Ergys Ristani (Facebook)<br>  Liang Zheng (Australian National University)<br> Xiatian Zhu (Queen Mary University of London)<br> 
      Jingdong Wang (Microsoft Research)<br> Shiliang Zhang (Peking University)<br>  Shaogang Gong (Queen Mary University of London)<br> 
      Qi Tian (University of Texas at San Antonio)<br> Carlo Tomasi (Duke University)<br> Richard Hartley (Australian National University)<br>    <br>

      <b>Program committee chairs:</b><br>
      TBD.<br><br>
      <!--<img src="img/calderara.jpg" class="figure-img img-fluid img-rounded" alt="" height="60px;">
      <img src="img/snoek.jpg" class="figure-img img-fluid img-rounded" alt="" height="60px;">
      <img src="img/jwang.jpg" class="figure-img img-fluid img-rounded" alt="" height="60px;">
      <img src="img/zhang.jpg" class="figure-img img-fluid img-rounded" alt="" height="60px;">
      <br/> Simone Calderara (University of Modena and Reggio Emilia)<br> Cees G.M. Snoek (University of Amsterdam)<br> Jingdong
      Wang (Microsoft Research)<br> Shiliang Zhang (Peking University)<br><br>-->

      <b>Program committee members:</b> Dapeng Chen, Wei-shi Zheng, Francesco Solera, Weiyao Lin, Giuseppe Lisanti, Slawomir Bak,
      Eyasu Zemene Mequanit, Li Zhang, Elyor Kodirov, Ying Zhang, Mang Ye, Zhedong Zheng, Zhun Zhong, Yonatan Tariku Tesfaye.<br><br>

      <!--<table>
  <tr><td>Horst Bischof</td><td>Roman Pflugfelder</td></tr>
  <tr><td>Octavia Camps</td><td>Amit Roy-Chowdhury</td></tr>
  <tr><td>Andrea Cavallaro</td><td>Peter Roth</td></tr>
  <tr><td>Chen Change Loy</td><td>Ling Shao</td></tr>
  <tr><td>Gerard Medioni</td><td>Xinchao Wang</td></tr>
  <tr><td>Christian Micheloni</td><td>Liang Zheng</td></tr>
  <tr><td>Vittorio Murino</td><td></td></tr>
</table>
-->

      <h3>
        <a id="contact" class="anchor" href="#designer-templates" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contact</h3>
      For any information, please send an <a href="mailto:liang.zheng@anu.edu.au;ergysristani@gmail.com;jingdw@microsoft.com">e-mail</a>      to Ergys Ristani, Liang Zheng and Jingdong Wang.

    </section>
    <footer>

    </footer>
  </div>
  <script src="./scripts/jquery-3.1.1.min.js"></script>
  <!--<script src="./javascripts/scale.fix.js"></script>-->
  <script>
    (function (i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r;
      i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date();
      a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
      a.async = 1;
      a.src = g;
      m.parentNode.insertBefore(a, m)
    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-89846544-1', 'auto');
    ga('send', 'pageview');


    $("#toggle-link").click(function () {
      $("#dis-similarities").toggle("slow");
    });
  </script>

</body>

</html>
